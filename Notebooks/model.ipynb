{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def stemming_tokenizer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    temp = text.replace(\"\\\\r\", \" \")\n",
    "    temp = temp.replace(\"\\\\n\", \" \")\n",
    "    return [stemmer.stem(w) for w in word_tokenize(temp)]\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "stop_words = stopwords.words('english')+list(string.punctuation)\n",
    "stemmed_stop_words = stemming_tokenizer(\" \".join(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "# https://github.com/alexandres/lexvec - https://www.dropbox.com/s/flh1fjynqvdsj4p/lexvec.commoncrawl.300d.W.pos.vectors.gz?dl=1\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('lexvec.enwiki+newscrawl.300d.W.pos.vectors', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(text, debug=False):\n",
    "    vec = np.zeros(300)\n",
    "    found_count = 0\n",
    "    total_count = 0\n",
    "    for word in stemming_tokenizer(text):\n",
    "        if word.lower() in stemmed_stop_words:\n",
    "            continue\n",
    "        total_count += 1\n",
    "        if word.lower() in model:\n",
    "            vec = vec + model[word.lower()]\n",
    "            found_count += 1\n",
    "    if debug:\n",
    "        print(found_count, total_count)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    help wanted,insiders-released,markdown,verific...\n",
       "1    bug,candidate,custom-editors,insiders-released...\n",
       "2                    bug,candidate,extensions,verified\n",
       "3                       Product-Launcher,Triage-Needed\n",
       "4    Issue-Bug,Product-Color Picker,Resolution-Fix-...\n",
       "Name: Label, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv('miniature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n",
      "3 5\n",
      "1 3\n",
      "4 6\n",
      "7 8\n",
      "37 69\n",
      "76 131\n",
      "74 129\n",
      "34 53\n",
      "13 16\n",
      "3 5\n",
      "5 7\n",
      "3 4\n",
      "0 2\n",
      "1 4\n",
      "6 7\n",
      "3 6\n",
      "4 7\n",
      "3 3\n",
      "7 7\n",
      "40 54\n",
      "6 13\n",
      "6 10\n",
      "104 144\n",
      "85 115\n"
     ]
    }
   ],
   "source": [
    "# Create vectors\n",
    "X_issue_title_wordvec = [get_vector(text, True) for text in data['IssueTitle']]\n",
    "X_issue_description_wordvec = [get_vector(text, True) for text in data['IssueDescription']]\n",
    "X_issue_label_wordvec = [get_vector(text, True) for text in data['Label']]\n",
    "Y_pr_title_wordvec = [get_vector(text, True) for text in data['PrTitle']]\n",
    "Y_pr_description_wordvec = [get_vector(text, True) for text in data['PrDescription']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split for all the data\n",
    "X_issue_title_wordvec_train, X_issue_title_wordvec_test, X_issue_description_wordvec_train, X_issue_description_wordvec_test, X_issue_label_wordvec_train, X_issue_label_wordvec_test, Y_pr_title_wordvec_train, Y_pr_title_wordvec_test, Y_pr_description_wordvec_train, Y_pr_description_wordvec_test = train_test_split(X_issue_title_wordvec, X_issue_description_wordvec, X_issue_label_wordvec, Y_pr_title_wordvec, Y_pr_description_wordvec, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=100)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "classifier = MLPRegressor(hidden_layer_sizes=(100))\n",
    "classifier.fit(X_issue_description_wordvec_train, Y_pr_description_wordvec_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99995536, 0.65876328, 0.64161949],\n",
       "       [0.6586168 , 0.99998496, 0.94782438],\n",
       "       [0.64182454, 0.9478992 , 0.99993288]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "y_pred = classifier.predict(X_issue_description_wordvec_train)\n",
    "cosine_similarity(y_pred, Y_pr_description_wordvec_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The spacing on markdown preview has headings (...\n",
       "1    <!-- ⚠️⚠️ Do Not Delete This! bug_report_templ...\n",
       "2    <!-- ⚠️⚠️ Do Not Delete This! bug_report_templ...\n",
       "Name: IssueDescription, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['IssueDescription'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This PR fixes #102036\\\\r\\\\n\\\\r\\\\n- So the first issue is that most elements have a margin-top and margin-bottom.\\\\r\\\\nIt made sense to remove the margin-top and let top elements push others down. (otherwise you fall into margin-collapse hell)\\\\r\\\\n- This means the body needs a padding on the top so that any first element has a gap (and not just the H1)\\\\r\\\\n- Headings have a smaller bottom margin so as to look more like a section\\\\r\\\\n- If 2 paragraphs are next to each other, the second paragraph reduces its top margin to bring them closer together.\\\\r\\\\n\\\\r\\\\n## Before\\\\r\\\\n![image](https://user-images.githubusercontent.com/936006/87351758-ce286c80-c551-11ea-80e5-13af706cd8ac.png)\\\\r\\\\n\\\\r\\\\n\\\\r\\\\n## After\\\\r\\\\n![image](https://user-images.githubusercontent.com/936006/87352076-5d358480-c552-11ea-9fa0-c5fcf3861712.png)\\\\r\\\\n\\\\r\\\\npings @mjbvz \\\\r\\\\n\\\\r\\\\n\\\\r\\\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['PrDescription'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
