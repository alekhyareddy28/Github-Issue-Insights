{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from joblib import dump, load\n",
    "\n",
    "def stemming_tokenizer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    temp = text.replace(\"\\\\r\", \" \")\n",
    "    temp = temp.replace(\"\\\\n\", \" \")\n",
    "    return [stemmer.stem(w) for w in word_tokenize(temp)]\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "stop_words = stopwords.words('english')+list(string.punctuation)\n",
    "stemmed_stop_words = stemming_tokenizer(\" \".join(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "# https://github.com/alexandres/lexvec - https://www.dropbox.com/s/flh1fjynqvdsj4p/lexvec.commoncrawl.300d.W.pos.vectors.gz?dl=1\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('lexvec.commoncrawl.300d.W.pos.neg3.vectors', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(text, debug=False):\n",
    "    vec = np.zeros(300)\n",
    "    found_count = 0\n",
    "    total_count = 0\n",
    "    for word in stemming_tokenizer(text):\n",
    "        if word.lower() in stemmed_stop_words:\n",
    "            continue\n",
    "        total_count += 1\n",
    "        if word.lower() in model:\n",
    "            vec = vec + model[word.lower()]\n",
    "            found_count += 1\n",
    "    if debug:\n",
    "        print(found_count, total_count)\n",
    "    return vec\n",
    "\n",
    "def save_model(model, filename='default.joblib'):\n",
    "    dump(model, filename)\n",
    "    \n",
    "def load_model(filename='default.joblib'):\n",
    "    return load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('..\\miniature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n",
      "5 5\n",
      "3 3\n",
      "6 6\n",
      "8 8\n",
      "4 5\n",
      "3 4\n",
      "7 7\n",
      "5 9\n",
      "1 2\n",
      "4 5\n",
      "5 7\n",
      "8 8\n",
      "0 2\n",
      "10 10\n",
      "40 70\n",
      "88 131\n",
      "92 129\n",
      "42 53\n",
      "15 16\n",
      "63 78\n",
      "7 12\n",
      "40 47\n",
      "102 137\n",
      "546 763\n",
      "188 295\n",
      "33 36\n",
      "12 14\n",
      "56 71\n",
      "34 44\n",
      "3 5\n",
      "5 7\n",
      "4 4\n",
      "0 2\n",
      "1 4\n",
      "0 2\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 2\n",
      "0 2\n",
      "0 3\n",
      "2 5\n",
      "0 1\n",
      "4 6\n",
      "6 7\n",
      "5 6\n",
      "7 7\n",
      "3 3\n",
      "7 7\n",
      "4 6\n",
      "6 6\n",
      "6 6\n",
      "6 6\n",
      "2 3\n",
      "1 2\n",
      "3 5\n",
      "10 10\n",
      "1 2\n",
      "12 12\n",
      "44 54\n",
      "8 13\n",
      "9 10\n",
      "116 144\n",
      "95 115\n",
      "17 21\n",
      "19 20\n",
      "9 10\n",
      "13 18\n",
      "14 22\n",
      "2 3\n",
      "147 178\n",
      "125 139\n",
      "5 7\n",
      "25 31\n"
     ]
    }
   ],
   "source": [
    "# Create vectors\n",
    "X_issue_title_wordvec = [get_vector(text, True) for text in data['IssueTitle']]\n",
    "X_issue_description_wordvec = [get_vector(text, True) for text in data['IssueDescription']]\n",
    "X_issue_label_wordvec = [get_vector(text, True) for text in data['Label']]\n",
    "Y_pr_title_wordvec = [get_vector(text, True) for text in data['PrTitle']]\n",
    "Y_pr_description_wordvec = [get_vector(text, True) for text in data['PrDescription']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split for all the data\n",
    "X_issue_title_wordvec_train, X_issue_title_wordvec_test, X_issue_description_wordvec_train, X_issue_description_wordvec_test, X_issue_label_wordvec_train, X_issue_label_wordvec_test, Y_pr_title_wordvec_train, Y_pr_title_wordvec_test, Y_pr_description_wordvec_train, Y_pr_description_wordvec_test = train_test_split(X_issue_title_wordvec, X_issue_description_wordvec, X_issue_label_wordvec, Y_pr_title_wordvec, Y_pr_description_wordvec, test_size=0.25, random_state=33, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "classifier = MLPRegressor(hidden_layer_sizes=(100), max_iter=500)\n",
    "classifier.fit(X_issue_description_wordvec_train, Y_pr_description_wordvec_train)\n",
    "modelFileName = \"testmodel.joblib\"\n",
    "save_model(classifier, modelFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99997806, 0.38256743, 0.61445984, 0.76526712, 0.74092145,\n",
       "        0.62459737, 0.54547813, 0.58231153, 0.61073225, 0.58135237,\n",
       "        0.36798945],\n",
       "       [0.42385593, 0.96421456, 0.55547583, 0.44032939, 0.51191259,\n",
       "        0.35696198, 0.4630528 , 0.45743175, 0.5761138 , 0.37627579,\n",
       "        0.33240415],\n",
       "       [0.61568919, 0.52033091, 0.98597826, 0.63781865, 0.66851146,\n",
       "        0.56573205, 0.55031831, 0.60056007, 0.64549759, 0.55262375,\n",
       "        0.39008007],\n",
       "       [0.76546671, 0.40633637, 0.61404987, 0.99999071, 0.9463143 ,\n",
       "        0.69843998, 0.60037007, 0.60548278, 0.69139797, 0.68410482,\n",
       "        0.37672298],\n",
       "       [0.74088647, 0.46978611, 0.63986108, 0.94634743, 0.99999951,\n",
       "        0.67722365, 0.60797223, 0.62716448, 0.70273058, 0.68903977,\n",
       "        0.37545292],\n",
       "       [0.62381208, 0.33081087, 0.55952719, 0.70111347, 0.68032929,\n",
       "        0.99870317, 0.53643193, 0.53219947, 0.56548714, 0.57746467,\n",
       "        0.41126143],\n",
       "       [0.54548568, 0.43505981, 0.5534485 , 0.59985528, 0.60761655,\n",
       "        0.53380305, 0.99999955, 0.53198854, 0.54083199, 0.56655435,\n",
       "        0.32178898],\n",
       "       [0.62279773, 0.43913306, 0.6126121 , 0.63614674, 0.6526258 ,\n",
       "        0.56150942, 0.54925693, 0.98221474, 0.52486272, 0.52499222,\n",
       "        0.32789206],\n",
       "       [0.64318295, 0.58735276, 0.69140292, 0.74312331, 0.7474862 ,\n",
       "        0.60540456, 0.58589286, 0.55058822, 0.95159998, 0.72196932,\n",
       "        0.41977882],\n",
       "       [0.61443191, 0.36730402, 0.57399425, 0.73202714, 0.74575205,\n",
       "        0.59909551, 0.58197161, 0.54525817, 0.73034536, 0.97299905,\n",
       "        0.37335256],\n",
       "       [0.53462488, 0.39869978, 0.59772963, 0.55932485, 0.57912637,\n",
       "        0.61365213, 0.47255034, 0.54729764, 0.58677904, 0.58268241,\n",
       "        0.50233728]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "fromFile = True\n",
    "if fromFile:\n",
    "    classifier = load_model(modelFileName)\n",
    "\n",
    "def predict_and_get_cosine_sim(x, y, clf):\n",
    "    y_pred = clf.predict(x)\n",
    "    return cosine_similarity(y_pred, y)\n",
    "\n",
    "predict_and_get_cosine_sim(X_issue_description_wordvec_train, Y_pr_description_wordvec_train, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  3, 12,  4],\n",
       "       [ 1,  8,  2, 11],\n",
       "       [ 2, 11,  4, 12],\n",
       "       [ 3,  4, 12, 11],\n",
       "       [ 4,  3, 12, 11],\n",
       "       [ 5, 11, 12,  3],\n",
       "       [ 6, 11,  4,  3],\n",
       "       [ 7, 11,  4, 12],\n",
       "       [ 8, 11,  4,  3],\n",
       "       [ 9, 12,  4,  3],\n",
       "       [11,  5, 12,  2],\n",
       "       [ 3,  4, 12, 11],\n",
       "       [ 4,  3, 12, 11],\n",
       "       [ 0,  2,  3, 12],\n",
       "       [ 0, 12,  3,  4]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_k_predictions(x, y, clf, k):\n",
    "    cosineMat = predict_and_get_cosine_sim(x, y, clf)\n",
    "    # Sort in descending order\n",
    "    return np.argsort(-1*cosineMat)[:, :k]\n",
    "\n",
    "# Test with PRs (train+test)\n",
    "get_top_k_predictions(X_issue_description_wordvec, Y_pr_description_wordvec, classifier, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The spacing on markdown preview has headings (h2,h3) in the middle between text, but they should be spaced less with the content underneath so it looks like a section. Right now the spacing looks even with the content below and above.\\\\r\\\\n\\\\r\\\\nHere is an example (using grey matter theme):\\\\r\\\\n<img width=\"676\" alt=\"markdown-preview\" src=\"https://user-images.githubusercontent.com/936006/87095255-50561f80-c238-11ea-8bcf-c4c2f023c3c1.png\">\\\\r\\\\n\\\\r\\\\nI\\'ve adjusted on photoshop what it should look like:\\\\r\\\\n<img width=\"676\" alt=\"markdown-preview (1)\" src=\"https://user-images.githubusercontent.com/936006/87095426-a034e680-c238-11ea-9897-b661e828630d.png\">\\\\r\\\\n\\\\r\\\\nIt\\'s only slight but the bottom one brings the heading down slightly so its more together.\\\\r\\\\nI looked into doing this but i could only find https://github.com/microsoft/vscode/blob/06f85af581281a3f45783329d375ecc7694930b4/extensions/markdown-language-features/media/markdown.css\\\\r\\\\n\\\\r\\\\n@mjbvz'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['IssueDescription'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
